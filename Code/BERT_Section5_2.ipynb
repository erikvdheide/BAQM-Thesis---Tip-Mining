{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Section5_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viyZQ1_48G5S"
      },
      "source": [
        "# Initial model: BERT [CLS] token as feature based Tip Mining using TensorFlow\n",
        "### Model: Bert-base (original)\n",
        "### Classifiers: LR, XGB and ANN\n",
        "\n",
        "@author: Erik van der Heide, EUR 2021-2022"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2ZiHWQh_bmo"
      },
      "source": [
        "### Setup your TensorFlow and Colab Runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnNnoIWA9oqh"
      },
      "source": [
        "Pre-modelling steps:\n",
        "1. Import tensorflow, check version\n",
        "2. Clone tensorflow official model garden repository from Github\n",
        "3. Install requirements to use tensorflow/models repository\n",
        "\n",
        "After doing the above, **restart** run-time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp6Sqkho8GCg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "30fc7f1a-a82c-4ffb-88ec-fedb91a4c245"
      },
      "source": [
        "\"\"\"\n",
        "!nvidia-smi\n",
        "print(\"\\n---\")\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.version.VERSION)\n",
        "print(\"\\n---\")\n",
        "\n",
        "!git clone --depth 1 -b v2.3.0 https://github.com/tensorflow/models.git\n",
        "print(\"\\n---\")\n",
        "\n",
        "!pip install -Uqr models/official/requirements.txt\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n!nvidia-smi\\nprint(\"\\n---\")\\n\\nimport tensorflow as tf\\nprint(\"TensorFlow version:\", tf.version.VERSION)\\nprint(\"\\n---\")\\n\\n!git clone --depth 1 -b v2.3.0 https://github.com/tensorflow/models.git\\nprint(\"\\n---\")\\n\\n!pip install -Uqr models/official/requirements.txt\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 439
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YejKAkYYHM_O"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdrjykqiHO3N"
      },
      "source": [
        "# Hyperparameters\n",
        "data_type = 'subset5'       # choose 'subsetX', where X=1,2,3,4,5 or 'full'\n",
        "max_seq_length = 64         # choose fixed maximum sequence length length\n",
        "batch_size = 32             # to process data sequentially"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6njO4nC7_lB9"
      },
      "source": [
        "### Import libraries and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTkShq7r_kPk"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import sys\n",
        "sys.path.append('models')\n",
        "import time\n",
        "\n",
        "from official.nlp.data import classifier_data_lib\n",
        "from official.nlp.bert import tokenization\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss\n",
        "from sklearn.metrics import plot_confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyFJ5zasBqjy",
        "outputId": "130b91f5-b260-488b-c552-557216983009"
      },
      "source": [
        "print(\"TF version  :\", tf.__version__)\n",
        "print(\"Eager mode  :\", tf.executing_eagerly())\n",
        "print(\"Hub version :\", hub.__version__)\n",
        "print(\"GPU is      :\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version  : 2.5.0\n",
            "Eager mode  : True\n",
            "Hub version : 0.12.0\n",
            "GPU is      : available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26twrFe9H-vS"
      },
      "source": [
        "Note: TensorFlow's *eager execution* is an imperative programming environment that evaluates operations immediately, without building graphs: operations return concrete values instead of constructing a computational graph to run later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1-26hy4H8NB"
      },
      "source": [
        "### Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fKIYAnH-z7b",
        "outputId": "683e8d6a-1399-462c-f05d-70f68fbc0f6c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRkBs1Bb_E_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf221c6-3e69-4c80-eb7d-b12416b99cb3"
      },
      "source": [
        "# Data for debugging\n",
        "if data_type=='subset': path =\"drive/MyDrive/Thesis BA&QM 2021/Data/td_clean_subset.csv\"\n",
        "if data_type=='full'  : path =\"drive/MyDrive/Thesis BA&QM 2021/Data/td_clean.csv\"     \n",
        "\n",
        "# Data for running\n",
        "if data_type=='subset1': path =\"drive/MyDrive/Thesis BA&QM 2021/Data/td_clean_subset1.csv\"\n",
        "if data_type=='subset2': path =\"drive/MyDrive/Thesis BA&QM 2021/Data/td_clean_subset2.csv\"\n",
        "if data_type=='subset3': path =\"drive/MyDrive/Thesis BA&QM 2021/Data/td_clean_subset3.csv\"\n",
        "if data_type=='subset4': path =\"drive/MyDrive/Thesis BA&QM 2021/Data/td_clean_subset4.csv\"\n",
        "if data_type=='subset5': path =\"drive/MyDrive/Thesis BA&QM 2021/Data/td_clean_subset5.csv\"\n",
        "\n",
        "# Read in data\n",
        "df = pd.read_csv(path, sep=\"\\t\", header=0)\n",
        "print(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/MyDrive/Thesis BA&QM 2021/Data/td_clean_subset5.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUqbpYRJ_NMN",
        "outputId": "64b79947-1248-49b7-fbdd-b69abd5e65a5"
      },
      "source": [
        "# Choose which data you want to use\n",
        "df = df[['sentence', 'tip']]\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df['tip'] = df['tip'].astype(int)\n",
        "print(f\"Tip distribution:\\n{df['tip'].value_counts()}\")\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tip distribution:\n",
            "0    3848\n",
            "1    3848\n",
            "Name: tip, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentence    object\n",
              "tip          int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 445
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ULIcmL3Fe1u"
      },
      "source": [
        "Create a train-validation-test split of 65-15-20 ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jk7LBL5c1gic",
        "outputId": "b1ef5193-5369-4659-8bd4-e93d345d1b13"
      },
      "source": [
        "if data_type[-1] in ['0','1','2','3','4','5','6','7','8','9']: \n",
        "  rand_state = int(data_type[-1]) \n",
        "else:\n",
        "  rand_state = 0\n",
        "print(f\"Random state: {rand_state} \\n\")\n",
        "\n",
        "# Train+validation and test split\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(df['sentence'], df['tip'], random_state=rand_state,  train_size=0.8, stratify=df['tip'])\n",
        "\n",
        "# Train and validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, random_state=0, train_size = 0.9998, stratify=y_trainval) # 0.65/0.8 , 0.9998\n",
        "\n",
        "# Reset indices\n",
        "#X_train.reset_index(drop=True, inplace=True), y_train.reset_index(drop=True, inplace=True)\n",
        "#X_val.reset_index(drop=True, inplace=True), y_val.reset_index(drop=True, inplace=True)\n",
        "#X_test.reset_index(drop=True, inplace=True), y_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Sizes & example:\n",
        "print(f\"Train size : {X_train.size} - {100*round(X_train.size/df.shape[0], 2)}% - ratio {round(y_train.value_counts(normalize=True)[0],1)}-{round(y_train.value_counts(normalize=True)[1],1)}\")\n",
        "print(f\"Valid size : {X_val.size} - {100*round(X_val.size/df.shape[0], 2)}% - ratio {round(y_val.value_counts(normalize=True)[0],1)}-{round(y_val.value_counts(normalize=True)[1],1)}\") \n",
        "print(f\"Test size  : {X_test.size} - {100*round(X_test.size/df.shape[0], 2)}% - ratio {round(y_test.value_counts(normalize=True)[0],1)}-{round(y_test.value_counts(normalize=True)[1],1)}\") \n",
        "#print(f\"\\nExample train data: X = '{X_train[0]}'  y = {y_train[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random state: 5 \n",
            "\n",
            "Train size : 6154 - 80.0% - ratio 0.5-0.5\n",
            "Valid size : 2 - 0.0% - ratio 0.5-0.5\n",
            "Test size  : 1540 - 20.0% - ratio 0.5-0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNHeKzH1Jj6O"
      },
      "source": [
        "### Download a pre-trained BERT model for TensorFlow Hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfmoCyGgQBmW"
      },
      "source": [
        "We load the model we want to use, including the WordPiece vocabulary, lower case command and the tokenizer. \n",
        "* BERT-Base: see https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2 for more details about the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRv8005bJqJF"
      },
      "source": [
        "label_list = [0,1]  # Label categories [0=non-tip, 1=tip]\n",
        "\n",
        "# Wrap a saved model in a Keras Layer\n",
        "URL = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\"\n",
        "bert_layer = hub.KerasLayer(URL, trainable=False) #if False, you freeze params\n",
        "\n",
        "# Tensor to numpy of vocab, lower case and tokenizer\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdezuvEkTkdp"
      },
      "source": [
        "Example of how the WordPiece tokenizer works ([CLS] and [SEP] tokens are still missing here):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQH0oAaUMij6",
        "outputId": "e3887f5e-ada3-4f3a-8deb-dfc758c88c74"
      },
      "source": [
        "example = \"hello, how are you doing today?\"\n",
        "print(f\"Example   : {example}\")\n",
        "print(f\"Tokens    : {tokenizer.wordpiece_tokenizer.tokenize(example)}\")\n",
        "print(f\"Token ids : {tokenizer.convert_tokens_to_ids(tokenizer.wordpiece_tokenizer.tokenize(example))}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example   : hello, how are you doing today?\n",
            "Tokens    : ['hello', '##,', 'how', 'are', 'you', 'doing', 'today', '##?']\n",
            "Token ids : [7592, 29623, 2129, 2024, 2017, 2725, 2651, 29632]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwpC0SAhNfLR"
      },
      "source": [
        "### Tokenize and preprocess text for BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b6jBoT8QNFD"
      },
      "source": [
        "Define a function to convert the input data to inputs for the BERT model:\n",
        "* input_ids: id's of tokens in sentence (e.g. [101 312 102 0 0])\n",
        "* input_mask: which tokens the model should focus on (e.g. [1 1 1 0 0])\n",
        "* segment_ids: only useful if we have input pairs (for us [0 0 0 0 0])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d08FIkiRfDJ_"
      },
      "source": [
        "def to_feature(text, label, label_list=label_list, max_seq_length=max_seq_length, tokenizer=tokenizer):\n",
        "  example = classifier_data_lib.InputExample(guid=None, # we work per data example\n",
        "                                             text_a=text.numpy(),\n",
        "                                             text_b=None, # we do not use paired dataa\n",
        "                                             label=label.numpy())\n",
        "  \n",
        "  feature = classifier_data_lib.convert_single_example(0, example, # 0th (only) example\n",
        "                                                       label_list, \n",
        "                                                       max_seq_length,\n",
        "                                                       tokenizer)\n",
        "  \n",
        "  return (feature.input_ids, feature.input_mask, feature.segment_ids, feature.label_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXG3I-KXinCa"
      },
      "source": [
        "### Wrap a Python function into a TensorFlow op for Eager Execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAnNrRJqi_UD"
      },
      "source": [
        "We want to use Dataset.map, but that runs in graph mode, and graph tensors do not have a value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhdtJfbQi9y7"
      },
      "source": [
        "# Function for Graph Tensors to regular Tensors\n",
        "# tf.py_function: wraps a python function into a TensorFlow op that executes it eagerly\n",
        "def to_feature_map(text, label):\n",
        "  input_ids, input_mask, segment_ids, label_id= tf.py_function(to_feature, \n",
        "                                                               inp=[text, label],\n",
        "                                                               Tout=[tf.int32,tf.int32,tf.int32,tf.int32])\n",
        "  input_ids.set_shape([max_seq_length])\n",
        "  input_mask.set_shape([max_seq_length])\n",
        "  segment_ids.set_shape([max_seq_length])\n",
        "  label_id.set_shape([])\n",
        "\n",
        "  x = {\n",
        "      'input_word_ids': input_ids,\n",
        "      'input_mask': input_mask,\n",
        "      'input_type_ids': segment_ids\n",
        "  }\n",
        "\n",
        "  return (x, label_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o94xndWtHft"
      },
      "source": [
        "### Add a classification head to the BERT layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyKFib501dkA"
      },
      "source": [
        "Create BERT model with its 3 inputs and a Dense layer with dropout."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1I2zHMithrM"
      },
      "source": [
        "# Building the model\n",
        "def create_model():\n",
        "  input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                         name=\"input_word_ids\")\n",
        "  input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                     name=\"input_mask\")\n",
        "  input_type_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                      name=\"input_type_ids\")\n",
        "  \n",
        "  pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, input_type_ids])\n",
        "  # pooled_output is CLS token, which we want to output\n",
        "  \n",
        "  model = tf.keras.Model(\n",
        "      inputs={\n",
        "        'input_word_ids': input_word_ids,\n",
        "        'input_mask': input_mask,\n",
        "        'input_type_ids': input_type_ids\n",
        "      },\n",
        "      outputs=pooled_output)\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDZhQyL_wTrV"
      },
      "source": [
        "### Collect [CLS] token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMDJwyltcr6f"
      },
      "source": [
        "Prepare the data into the right format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F65N6E4XGhoC",
        "outputId": "f55f26e0-b4d5-47fa-bf4b-d5ab21355a3c"
      },
      "source": [
        "with tf.device('/cpu:0'): # run on cpu\n",
        "  train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "  valid_data = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "  test_data = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "  # Show the first tensor slice of the training data [take(1) is only the first (text, label) pair]\n",
        "for text, label in train_data.take(1):\n",
        "  print(text.numpy())\n",
        "  print(label.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'More caulk ended up on the glass and exterior walls of my house than in the cracks around the windows.'\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmG-dzb0oS8j"
      },
      "source": [
        "with tf.device('/cpu:0'):\n",
        "  # Train\n",
        "  train_data = (train_data.map(to_feature_map,\n",
        "                               num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  .batch(batch_size,drop_remainder=False)\n",
        "  .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "  # Valid\n",
        "  valid_data = (valid_data.map(to_feature_map,\n",
        "                               num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  .batch(batch_size,drop_remainder=False)\n",
        "  .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "  # Test\n",
        "  test_data = (test_data.map(to_feature_map,\n",
        "                               num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  .batch(batch_size,drop_remainder=False)\n",
        "  .prefetch(tf.data.experimental.AUTOTUNE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pm8HRBfGTqbI"
      },
      "source": [
        "We feed the training data to the model and save the hidden state of the [CLS] token, as this can be seen as a sentence representation. We only take the training data and not validation data to make a fair comparison with other models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFqzAHRkwXKO",
        "outputId": "5961af0e-ab56-436b-c11a-ad35df01f4f6"
      },
      "source": [
        "# Create the model instance\n",
        "model = create_model()\n",
        "\n",
        "# Collect hidden state\n",
        "start = time.time()\n",
        "train_cls = model.predict(train_data)\n",
        "end = time.time()\n",
        "print(\"Elapsed time tokenization: \", (end-start)/60, \"min\\n\")\n",
        "\n",
        "print(\"Shape   : \", train_cls.shape)\n",
        "print(\"Example : \", train_cls[0][0:10],\"...\")\n",
        "\n",
        "train_labels = y_train\n",
        "print(\"Shape labels : \", train_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elapsed time tokenization:  0.8312004844347636 min\n",
            "\n",
            "Shape   :  (6154, 768)\n",
            "Example :  [-0.83198625 -0.38668388 -0.8685194   0.5719345   0.7176042  -0.18473779\n",
            "  0.7026555   0.10160547 -0.6444204  -0.99992555] ...\n",
            "Shape labels :  (6154,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIVyv48xhsA9"
      },
      "source": [
        "Do the same for the validation data and test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9x0xQQs0HYOL",
        "outputId": "884f0465-2101-46b1-8386-b39a406e595a"
      },
      "source": [
        "# Validation data\n",
        "start = time.time()\n",
        "valid_cls = model.predict(valid_data)\n",
        "end = time.time()\n",
        "print(\"Elapsed time tokenization: \", (end-start)/60, \"min\\n\")\n",
        "\n",
        "print(\"Shape   : \", valid_cls.shape)\n",
        "print(\"Example : \", valid_cls[0][0:10],\"...\")\n",
        "\n",
        "valid_labels = y_val\n",
        "print(\"Shape labels : \", valid_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elapsed time tokenization:  0.0009561220804850261 min\n",
            "\n",
            "Shape   :  (2, 768)\n",
            "Example :  [-0.64129215 -0.3321332  -0.928082    0.69086784  0.8137915  -0.11740386\n",
            "  0.76416     0.15133017 -0.7383154  -0.9999286 ] ...\n",
            "Shape labels :  (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lskGnD6whtpR",
        "outputId": "1d7102e6-f367-4954-ead4-a6d16fed2805"
      },
      "source": [
        "# Test data\n",
        "start = time.time()\n",
        "test_cls = model.predict(test_data)\n",
        "end = time.time()\n",
        "print(\"Elapsed time tokenization: \", (end-start)/60, \"min\\n\")\n",
        "\n",
        "print(\"Shape   : \", test_cls.shape)\n",
        "print(\"Example : \", test_cls[0][0:10],\"...\")\n",
        "\n",
        "test_labels = y_test\n",
        "print(\"Shape labels : \", test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elapsed time tokenization:  0.341607129573822 min\n",
            "\n",
            "Shape   :  (1540, 768)\n",
            "Example :  [-0.7388773  -0.28507316 -0.8101706   0.6603096   0.64142144 -0.26226175\n",
            "  0.45954365  0.2608935  -0.539273   -0.9998473 ] ...\n",
            "Shape labels :  (1540,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91zBVTER4Flz"
      },
      "source": [
        "### Train classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S72muj8qJDaC"
      },
      "source": [
        "Choose your classifier (can specify this after preparing the data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjUyI_WjJrwB"
      },
      "source": [
        "classifier_type = 'lr'      # choose classifier 'LR', 'XGB', or 'ANN'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDXBskBUfiVb"
      },
      "source": [
        "Classifier 1: **Logistic Regression** (LR). \\\\\n",
        "No parameter tuning is done. \\\\\n",
        "The solver \"liblinear\" is used to take care of a bug in the LR model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg4_sCy2fPOg"
      },
      "source": [
        "if classifier_type.lower() == 'lr':\n",
        "  classifier = LogisticRegression(random_state=1, solver='liblinear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh7efiv2fvgl"
      },
      "source": [
        "Classifier 2: **eXtreme Gradient Boosting** (XGB). \\\\\n",
        "Possibility to tune on validation set, e.g. max. depth $\\in [5,10,15,20,25,30]$, but that requires about 1,5 min per parameter value.\n",
        "Probeer ook sklearn.ensemble.GradientBoostingClassifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QM1nvFdfy2e"
      },
      "source": [
        "if classifier_type.lower() == 'xgb':\n",
        "  \"\"\" # Hyperparameter tuning\n",
        "  start = time.time()\n",
        "  best_metric = 0\n",
        "  best_max_depth = 0\n",
        "  for depth in range(5, 35, 5):\n",
        "    classifier_tuning = XGBClassifier(random_state=1, max_depth=depth)\n",
        "    classifier_tuning.fit(train_cls, train_labels)\n",
        "    preds_tuning = classifier.predict(valid_cls)\n",
        "    metric = accuracy_score(valid_labels, preds_tuning)\n",
        "    if metric > best_metric:\n",
        "      best_metric = metric\n",
        "      best_max_depth = depth\n",
        "  classifier = XGBClassifier(random_state=1, max_depth=best_max_depth)\n",
        "  end = time.time()\n",
        "  print(\"Elapsed time tuning: \", (end-start)/60, \"min\")\n",
        "  \"\"\"\n",
        "  classifier = XGBClassifier(random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb77n33SfzSt"
      },
      "source": [
        "Classifier 3: **Artificial Neural Network** (ANN). \\\\\n",
        "Parameter tuning is done on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dC0Y4uBgV3F"
      },
      "source": [
        "if classifier_type.lower() == 'ann':\n",
        "  classifier = tf.keras.models.Sequential()\n",
        "  classifier.add(tf.keras.layers.Dropout(rate=0.1))\n",
        "  classifier.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "  classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2Ne1aJjgf94"
      },
      "source": [
        "### Fit classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0esNiialneT",
        "outputId": "fa4c860c-ea39-457e-9982-0f6e97db28b2"
      },
      "source": [
        "train_cls.shape, train_labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6154, 768), (6154,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 461
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYebasZigfpq",
        "outputId": "f9cc0de2-672c-4236-8fc1-dd095a02731e"
      },
      "source": [
        "print(\"Classifier: \", classifier_type)\n",
        "start = time.time()\n",
        "if classifier_type == 'ann':\n",
        "  classifier.fit(train_cls, train_labels, batch_size = 32, epochs = 10, validation_data=(valid_cls, valid_labels))\n",
        "else:\n",
        "  classifier.fit(train_cls, train_labels)\n",
        "end = time.time()\n",
        "print(\"Elapsed time classification: \", (end-start)/60, \"min\\n\")\n",
        "if classifier_type == 'ann':\n",
        "  preds = classifier.predict_classes(test_cls)\n",
        "else:\n",
        "  preds = classifier.predict(test_cls)\n",
        "preds_prob = classifier.predict_proba(test_cls)\n",
        "if classifier_type != 'ann':\n",
        "  preds_prob = preds_prob[:,1]\n",
        "print(preds)\n",
        "print(preds_prob)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifier:  lr\n",
            "Elapsed time classification:  0.0469019889831543 min\n",
            "\n",
            "[1 0 1 ... 1 1 0]\n",
            "[0.59581269 0.30985156 0.90095972 ... 0.78875565 0.54073568 0.05169515]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhgOJfq5kOGv",
        "outputId": "951d96d1-3e14-4ba9-f093-0f3bf3b3d74d"
      },
      "source": [
        "# Evaluation metrics\n",
        "PR   = precision_score(test_labels, preds)\n",
        "RC   = recall_score(test_labels, preds)\n",
        "F1   = f1_score(test_labels, preds)\n",
        "ACC  = accuracy_score(test_labels, preds)\n",
        "AUC  = roc_auc_score(test_labels, preds_prob)\n",
        "LOSS = log_loss(test_labels, preds_prob)\n",
        "print(f\"Precision : {PR}\")\n",
        "print(f\"Recall    : {RC}\")\n",
        "print(f\"F1-score  : {F1}\")\n",
        "print(f\"Accuracy  : {ACC}\")\n",
        "print(f\"AUC       : {AUC}\")\n",
        "print(f\"Loss      : {LOSS}\")\n",
        "\n",
        "print(f\"COPY:  {round(PR,4)}, {round(RC,4)}, {round(F1,4)}, {round(ACC,4)}, {round(AUC,4)}, {round(LOSS,4)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision : 0.7341935483870968\n",
            "Recall    : 0.7389610389610389\n",
            "F1-score  : 0.736569579288026\n",
            "Accuracy  : 0.7357142857142858\n",
            "AUC       : 0.811310507674144\n",
            "Loss      : 0.529888147352543\n",
            "COPY:  0.7342, 0.739, 0.7366, 0.7357, 0.8113, 0.5299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "@references: \n",
        "* https://www.coursera.org/learn/fine-tune-bert-tensorflow/supplement/zbuz9/resources-on-how-bert-works\n",
        "* https://www.tensorflow.org/text/tutorials/classify_text_with_bert"
      ],
      "metadata": {
        "id": "AzTlXMupjn5w"
      }
    }
  ]
}